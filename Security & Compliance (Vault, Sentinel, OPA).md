# ğŸ” TOPIC 8: Security & Compliance â€” Vault, Sentinel & OPA

---

## ğŸŸ¢ BEGINNER LEVEL

### What is Security & Compliance in Terraform? (Simple Terms)

Imagine you're running a **hospital**. Doctors can prescribe medicine, but there are strict rules:
- Only licensed doctors can prescribe controlled substances
- Every prescription must be logged and audited
- Certain dangerous drugs require supervisor approval
- Patient data must be encrypted at all times
- Nobody can access the medication vault without proper authorization

**Terraform Security & Compliance is the same concept for infrastructure:**

```
Without Security Controls          With Security Controls
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Any dev can create open S3         Policy blocks public S3 buckets
Passwords hardcoded in .tf files   Vault provides secrets dynamically
No audit trail of changes          Every change logged and attributed
Prod credentials on laptops        Short-lived credentials via Vault
Anyone can deploy anything          Only approved resource types allowed
```

---

### The Three Pillars of Terraform Security

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 TERRAFORM SECURITY PILLARS                      â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  HashiCorp    â”‚  â”‚   Sentinel    â”‚  â”‚       OPA         â”‚   â”‚
â”‚  â”‚    Vault      â”‚  â”‚               â”‚  â”‚  (Open Policy     â”‚   â”‚
â”‚  â”‚               â”‚  â”‚               â”‚  â”‚    Agent)         â”‚   â”‚
â”‚  â”‚ SECRETS       â”‚  â”‚  POLICY       â”‚  â”‚  POLICY           â”‚   â”‚
â”‚  â”‚ MANAGEMENT    â”‚  â”‚  ENFORCEMENT  â”‚  â”‚  AS CODE          â”‚   â”‚
â”‚  â”‚               â”‚  â”‚  (TF Cloud/   â”‚  â”‚  (Open Source)    â”‚   â”‚
â”‚  â”‚ "What secrets â”‚  â”‚   Enterprise) â”‚  â”‚                   â”‚   â”‚
â”‚  â”‚  can you use?"â”‚  â”‚ "What infra   â”‚  â”‚ "What infra       â”‚   â”‚
â”‚  â”‚               â”‚  â”‚  is allowed?" â”‚  â”‚  is allowed?"     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚       â†•                    â†•                    â†•               â”‚
â”‚  Dynamic secrets       Pre-apply gates      Pre/post gates      â”‚
â”‚  Lease management      TFC/TFE native       Any CI/CD system    â”‚
â”‚  Audit logging         Rego-compatible      Conftest tool       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Real-World Analogy

```
VAULT  =  Bank's Secure Vault Room
          - Only authorized people get access
          - Tracks who accessed what and when
          - Access expires after a set time
          - You get a temporary key, not a permanent one

SENTINEL =  Bank's Internal Policy Engine
            - Corporate rule: "Loans above $50k need director approval"
            - Checked BEFORE any transaction is processed
            - Cannot be bypassed even by senior staff
            - Policies written by compliance team

OPA     =  Bank's External Compliance Auditor
           - Independent of the bank's systems
           - Can audit any system (not just the bank's)
           - Writes reports: pass/warn/deny
           - Open standard, works with any platform
```

---

### Why These Tools Matter

```bash
# WITHOUT these tools â€” real risks:

# Risk 1: Hardcoded secrets in code (ends up in Git history!)
resource "aws_db_instance" "main" {
  password = "MySecret123!"    # â† LEAKED! Anyone with repo access sees this
}

# Risk 2: Overly permissive infrastructure
resource "aws_s3_bucket" "data" {
  acl = "public-read"          # â† Customer data exposed to internet!
}

# Risk 3: Non-compliant resources
resource "aws_instance" "web" {
  instance_type = "m5.24xlarge"  # â† $3,000/month! No budget check
}

# Risk 4: No audit trail
# Who created this? When? Why? What changed? Nobody knows.
```

---

### Basic Concepts at a Glance

```
VAULT:    Dynamic secrets engine
          terraform plan â†’ asks Vault for DB credentials
          Vault issues temp credentials (expire in 1hr)
          Next plan â†’ new temp credentials

SENTINEL: Policy-as-code (HashiCorp native)
          terraform plan finishes â†’
          Sentinel evaluates plan against policies â†’
          PASS: apply proceeds
          FAIL: apply blocked, error shown

OPA:      Policy-as-code (open source, cloud native)
          Works with: Terraform, Kubernetes, APIs, microservices
          Conftest tool makes it easy to use with Terraform
          terraform show -json tfplan â†’ conftest test â†’ PASS/FAIL
```

---

### Common Beginner Mistakes

```hcl
# âŒ MISTAKE 1: Using Vault provider without lease management
provider "vault" {
  address = "https://vault.mycompany.com"
  token   = "hvs.hardcoded_token"    # Never hardcode Vault tokens!
}
# âœ… Use environment variables or auth methods (AppRole, AWS, etc.)

# âŒ MISTAKE 2: Not understanding Sentinel is TFC/TFE only
# Sentinel runs ONLY in Terraform Cloud or Terraform Enterprise
# For open-source Terraform: use OPA/Conftest instead

# âŒ MISTAKE 3: Writing OPA policies that are too strict
# Block on every tiny issue â†’ developers bypass by not using Terraform
# âœ… Use soft-mandatory (warn) for most rules, hard-mandatory for critical

# âŒ MISTAKE 4: Not rotating Vault dynamic credentials
# Dynamic credentials have a TTL (time-to-live)
# Terraform apply might take 45 min â†’ credentials expire â†’ mid-apply failure
# âœ… Set credential TTL longer than your longest apply

# âŒ MISTAKE 5: Storing Vault token in terraform.tfvars
vault_token = "hvs.CAESIDdGkH..."    # In terraform.tfvars â†’ ends up in Git!
# âœ… Use: export VAULT_TOKEN=$(vault login -method=aws -field=token)
```

---

## ğŸŸ¡ INTERMEDIATE LEVEL

### HashiCorp Vault â€” Complete Integration

**Vault Architecture with Terraform:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VAULT + TERRAFORM FLOW                       â”‚
â”‚                                                                 â”‚
â”‚  Terraform          Vault Server         AWS/DB/Cloud           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”‚
â”‚                                                                 â”‚
â”‚  init          â”€â”€â”€â–º Authenticate â”€â”€â”€â”€â–º  Verify identity        â”‚
â”‚  (AppRole/         (Issue token)                                â”‚
â”‚   AWS auth)    â—„â”€â”€â”€ Token returned                              â”‚
â”‚                                                                 â”‚
â”‚  plan/apply    â”€â”€â”€â–º Request secret â”€â”€â–º  Check policy           â”‚
â”‚                â—„â”€â”€â”€ Temp credentials â—„â”€â”€ Create temp user       â”‚
â”‚                                         (e.g., DB user)        â”‚
â”‚  Creates DB    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚
â”‚  with temp creds                        DB created              â”‚
â”‚                                                                 â”‚
â”‚  [1 hour later]    â—„â”€â”€ Lease expires    Temp user deleted       â”‚
â”‚                                         automatically           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Setting Up Vault Provider:**

```hcl
# providers.tf
terraform {
  required_providers {
    vault = {
      source  = "hashicorp/vault"
      version = "~> 3.20"
    }
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

# â”€â”€ Method 1: Environment Variables (simplest, for local dev) â”€â”€â”€â”€
# export VAULT_ADDR="https://vault.mycompany.com"
# export VAULT_TOKEN="hvs.CAESID..."
provider "vault" {}    # Reads VAULT_ADDR and VAULT_TOKEN automatically


# â”€â”€ Method 2: AppRole (for CI/CD pipelines) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
provider "vault" {
  address = "https://vault.mycompany.com"

  auth_login {
    path = "auth/approle/login"

    parameters = {
      role_id   = var.vault_role_id     # From CI/CD secret
      secret_id = var.vault_secret_id   # From CI/CD secret (wrapped)
    }
  }
}


# â”€â”€ Method 3: AWS Auth (for resources running IN AWS) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# EC2, Lambda, ECS, etc. can auth to Vault using their IAM identity
provider "vault" {
  address = "https://vault.mycompany.com"

  auth_login_aws {
    role = "terraform-role"    # Vault role that maps to AWS IAM role
    # Vault verifies with AWS STS - no static credentials needed!
  }
}


# â”€â”€ Method 4: Kubernetes Auth (for K8s workloads) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
provider "vault" {
  address = "https://vault.mycompany.com"

  auth_login_kubernetes {
    role = "terraform-role"
    jwt  = file("/var/run/secrets/kubernetes.io/serviceaccount/token")
  }
}
```

---

**Vault Secret Engines:**

```hcl
# â”€â”€ 1. KV (Key-Value) Secrets Engine â€” Static Secrets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Read a static secret from Vault KV v2
data "vault_kv_secret_v2" "app_config" {
  mount = "secret"                    # The KV mount path
  name  = "myapp/production/config"   # Secret path within mount
}

locals {
  api_key      = data.vault_kv_secret_v2.app_config.data["api_key"]
  db_password  = data.vault_kv_secret_v2.app_config.data["db_password"]
  stripe_key   = data.vault_kv_secret_v2.app_config.data["stripe_secret_key"]
}

# Use in resource
resource "aws_ssm_parameter" "api_key" {
  name  = "/myapp/prod/api_key"
  type  = "SecureString"
  value = local.api_key
}


# â”€â”€ 2. AWS Secrets Engine â€” Dynamic AWS Credentials â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# First: Configure Vault AWS engine (usually done by Vault admin)
resource "vault_aws_secret_backend" "aws" {
  path = "aws"

  access_key = var.vault_aws_access_key    # Master credentials for Vault
  secret_key = var.vault_aws_secret_key
  region     = "us-east-1"
}

resource "vault_aws_secret_backend_role" "terraform_role" {
  backend         = vault_aws_secret_backend.aws.path
  name            = "terraform-deploy"
  credential_type = "iam_user"

  policy_document = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect   = "Allow"
      Action   = ["s3:*", "ec2:*", "rds:*"]
      Resource = "*"
    }]
  })
}

# Now Terraform can request dynamic AWS credentials
data "vault_aws_access_credentials" "deploy" {
  backend = "aws"
  role    = "terraform-deploy"
  type    = "iam_user"
}

# Configure AWS provider with dynamic Vault credentials!
provider "aws" {
  access_key = data.vault_aws_access_credentials.deploy.access_key
  secret_key = data.vault_aws_access_credentials.deploy.secret_key
  token      = data.vault_aws_access_credentials.deploy.security_token
  region     = "us-east-1"
}


# â”€â”€ 3. Database Secrets Engine â€” Dynamic DB Credentials â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Configure Vault database engine (done by Vault admin)
resource "vault_database_secret_backend_connection" "postgres" {
  backend       = "database"
  name          = "prod-postgres"
  allowed_roles = ["app-role", "readonly-role", "terraform-role"]

  postgresql {
    connection_url = "postgresql://{{username}}:{{password}}@postgres.mycompany.com:5432/appdb"
    # Note: {{username}} and {{password}} are Vault template variables
    # Vault uses these to create and rotate credentials
  }
}

resource "vault_database_secret_backend_role" "app_role" {
  backend             = "database"
  name                = "app-role"
  db_name             = vault_database_secret_backend_connection.postgres.name
  creation_statements = [
    "CREATE ROLE \"{{name}}\" WITH LOGIN PASSWORD '{{password}}' VALID UNTIL '{{expiration}}';",
    "GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO \"{{name}}\";"
  ]
  revocation_statements = [
    "DROP ROLE IF EXISTS \"{{name}}\";"
  ]
  default_ttl = "1h"    # Credentials expire in 1 hour
  max_ttl     = "24h"   # Maximum 24 hours with renewal
}

# Terraform requests dynamic DB credentials
data "vault_database_secret_backend_creds" "app_creds" {
  backend = "database"
  role    = "app-role"
}

# Use dynamic credentials in RDS
resource "aws_db_instance" "app" {
  identifier     = "myapp-prod"
  engine         = "postgres"
  instance_class = "db.t3.medium"

  # These credentials are temporary and will expire!
  username = data.vault_database_secret_backend_creds.app_creds.username
  password = data.vault_database_secret_backend_creds.app_creds.password

  # After apply, Vault manages the rotation automatically
}


# â”€â”€ 4. PKI Secrets Engine â€” Dynamic TLS Certificates â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

data "vault_pki_secret_backend_cert" "app_cert" {
  backend     = "pki"
  name        = "myapp-role"
  common_name = "api.myapp.com"
  ttl         = "720h"    # 30 days
  ip_sans     = ["10.0.1.5"]
}

resource "aws_acm_certificate" "app" {
  # Import Vault-generated cert into ACM
  private_key       = data.vault_pki_secret_backend_cert.app_cert.private_key
  certificate_body  = data.vault_pki_secret_backend_cert.app_cert.certificate
  certificate_chain = data.vault_pki_secret_backend_cert.app_cert.ca_chain
}
```

---

**Vault Transit Engine â€” Encrypt Terraform State:**

```hcl
# Encrypt sensitive data before storing in state
# (Even if state is compromised, data is encrypted)

resource "vault_transit_secret_backend_key" "state_key" {
  backend          = "transit"
  name             = "terraform-state-key"
  type             = "aes256-gcm96"
  deletion_allowed = false
}

# Encrypt a value using Vault Transit
data "vault_transit_encrypt" "sensitive_config" {
  backend   = "transit"
  key       = vault_transit_secret_backend_key.state_key.name
  plaintext = base64encode(jsonencode({
    api_key    = var.api_key
    db_password = var.db_password
  }))
}

# Store encrypted ciphertext (safe to have in state)
resource "aws_ssm_parameter" "encrypted_config" {
  name  = "/myapp/prod/encrypted_config"
  type  = "String"    # Not SecureString â€” Vault handles encryption
  value = data.vault_transit_encrypt.sensitive_config.ciphertext
  # Ciphertext is: vault:v1:ABC123... (only Vault can decrypt this)
}
```

---

**Vault Audit Logging â€” Complete Audit Trail:**

```hcl
# Enable audit logging in Vault (every secret access is logged)
resource "vault_audit" "file_audit" {
  type = "file"

  options = {
    file_path   = "/var/log/vault/audit.log"
    log_raw     = "false"    # Don't log secret values!
    format      = "json"
    hmac_accessor = "true"   # HMAC-hash sensitive identifiers
  }
}

resource "vault_audit" "syslog_audit" {
  type = "syslog"

  options = {
    tag      = "vault"
    facility = "AUTH"
  }
}

# Every secret access creates a log entry like:
# {
#   "time": "2024-01-15T14:30:00Z",
#   "type": "response",
#   "auth": { "client_token": "hmac-sha256:abc123", "accessor": "hmac-sha256:def456",
#             "entity_id": "terraform-ci-runner" },
#   "request": { "id": "xyz789", "operation": "read",
#                "path": "secret/data/myapp/prod/config" },
#   "response": { "data": { "keys": ["api_key", "db_password"] } }
#                               â†‘ Keys logged but NOT values
# }
```

---

### Sentinel â€” Policy as Code for Terraform Cloud/Enterprise

**What Sentinel Is:**

```
Sentinel is HashiCorp's policy-as-code framework.
It runs AFTER terraform plan but BEFORE terraform apply.
It's a gate â€” policies decide if apply is allowed to proceed.

Policy enforcement levels:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ADVISORY    â†’ Always passes. Just logs violations. (informational)
SOFT-MANDATORY â†’ Passes unless overridden. Senior engineer can bypass.
HARD-MANDATORY â†’ Always enforced. Cannot be overridden. Ever.
```

**Sentinel Policy Language:**

```python
# policies/restrict-instance-types.sentinel
# Policy: Only allow approved EC2 instance types

# Import Terraform plan data
import "tfplan/v2" as tfplan

# Define allowed instance types
allowed_types = [
  "t3.micro",
  "t3.small",
  "t3.medium",
  "t3.large",
  "m5.large",
  "m5.xlarge",
  "m5.2xlarge",
]

# Find all EC2 instances in the plan
all_ec2_instances = filter tfplan.resource_changes as _, rc {
  rc.type is "aws_instance" and
  rc.mode is "managed" and
  rc.change.actions is not ["delete"]
}

# Check each instance
violations = filter all_ec2_instances as _, instance {
  instance.change.after.instance_type not in allowed_types
}

# Generate helpful error messages
msgs = map violations as _, v {
  v.address + " uses instance type '" +
  v.change.after.instance_type +
  "' which is not in the approved list: " +
  allowed_types
}

# The main rule â€” this determines pass/fail
main = rule {
  length(violations) is 0
} else {
  print("POLICY VIOLATION - Unapproved instance types:")
  print(msgs)
  false
}
```

```python
# policies/require-tags.sentinel
# Policy: All resources must have required tags

import "tfplan/v2" as tfplan

required_tags = ["Environment", "Owner", "CostCenter", "ManagedBy"]

# Resources that must have tags
taggable_resources = [
  "aws_instance",
  "aws_s3_bucket",
  "aws_db_instance",
  "aws_lb",
  "aws_vpc",
]

# Find all taggable resources being created/updated
all_resources = filter tfplan.resource_changes as _, rc {
  rc.type in taggable_resources and
  rc.mode is "managed" and
  rc.change.actions is not ["delete"]
}

# Check each resource for missing tags
violations = []

for all_resources as address, resource {
  tags = resource.change.after.tags else {}

  for required_tags as tag {
    if tag not in tags {
      append(violations, address + " is missing required tag: " + tag)
    }
  }
}

main = rule {
  length(violations) is 0
} else {
  print("POLICY VIOLATION - Missing required tags:")
  print(violations)
  false
}
```

```python
# policies/restrict-public-s3.sentinel
# Policy: No S3 buckets with public access

import "tfplan/v2" as tfplan

# Find S3 public access block resources
s3_public_access_blocks = filter tfplan.resource_changes as _, rc {
  rc.type is "aws_s3_bucket_public_access_block" and
  rc.mode is "managed" and
  rc.change.actions is not ["delete"]
}

# Find S3 buckets without public access block
s3_buckets = filter tfplan.resource_changes as _, rc {
  rc.type is "aws_s3_bucket" and
  rc.mode is "managed" and
  rc.change.actions is not ["delete"]
}

# Check public access blocks are properly configured
violations = filter s3_public_access_blocks as _, resource {
  resource.change.after.block_public_acls       is not true or
  resource.change.after.block_public_policy     is not true or
  resource.change.after.ignore_public_acls      is not true or
  resource.change.after.restrict_public_buckets is not true
}

main = rule {
  length(violations) is 0
} else {
  print("POLICY VIOLATION - S3 buckets with public access:")
  print(map violations as _, v { v.address })
  false
}
```

```python
# policies/cost-estimation.sentinel
# Policy: Block resources estimated to cost more than $500/month
# (Requires Terraform Cloud Cost Estimation to be enabled)

import "tfcost" as cost

# Maximum monthly cost in USD
max_monthly_cost = 500

# Check total cost estimate
main = rule {
  cost.proposed.total_monthly_cost < max_monthly_cost
} else {
  print("POLICY VIOLATION - Estimated cost exceeds budget:")
  print("  Proposed monthly cost: $" + string(cost.proposed.total_monthly_cost))
  print("  Maximum allowed:       $" + string(max_monthly_cost))
  print("  Please optimize your infrastructure or request a budget exception.")
  false
}
```

**Sentinel Configuration:**

```python
# sentinel.hcl â€” Policy set configuration (in Terraform Cloud)

policy "restrict-instance-types" {
  source            = "./policies/restrict-instance-types.sentinel"
  enforcement_level = "hard-mandatory"   # Cannot be bypassed
}

policy "require-tags" {
  source            = "./policies/require-tags.sentinel"
  enforcement_level = "soft-mandatory"   # Can be overridden with reason
}

policy "restrict-public-s3" {
  source            = "./policies/restrict-public-s3.sentinel"
  enforcement_level = "hard-mandatory"
}

policy "cost-estimation" {
  source            = "./policies/cost-estimation.sentinel"
  enforcement_level = "soft-mandatory"
}

# Modules for reusable policy logic
module "aws-functions" {
  source = "./modules/aws-functions.sentinel"
}

module "tfplan-functions" {
  source = "./modules/tfplan-functions.sentinel"
}
```

---

### OPA (Open Policy Agent) â€” Cloud-Native Policy Engine

**Why OPA over Sentinel:**

```
OPA ADVANTAGES:
âœ… Open source â€” no vendor lock-in
âœ… Works with ANY system (K8s, APIs, Terraform, Envoy, etc.)
âœ… Widely adopted â€” CNCF graduated project
âœ… Works with open-source Terraform
âœ… Large community, many pre-built policies
âœ… Rego language is powerful and expressive

SENTINEL ADVANTAGES:
âœ… Native Terraform Cloud/Enterprise integration
âœ… Tighter integration with Terraform plan data
âœ… Simpler language for Terraform-specific policies
âœ… Cost estimation integration
âœ… HashiCorp support
```

**OPA with Conftest â€” Terraform Integration:**

```bash
# Install conftest
brew install conftest  # macOS
# OR
wget https://github.com/open-policy-agent/conftest/releases/download/v0.46.0/conftest_0.46.0_Linux_x86_64.tar.gz

# Generate Terraform plan as JSON
terraform plan -out=tfplan
terraform show -json tfplan > plan.json

# Run policies against plan
conftest test plan.json --policy ./policies/

# Output:
# FAIL - plan.json - main - S3 bucket 'aws_s3_bucket.data' must not be public
# FAIL - plan.json - main - EC2 instance 'aws_instance.web' missing required tag: Owner
# PASS - plan.json - Approved instance type t3.large
```

---

**OPA Rego Policies â€” Complete Examples:**

```rego
# policies/terraform/s3_security.rego
package terraform.s3

import future.keywords.if
import future.keywords.in

# â”€â”€ Rule 1: No public S3 buckets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
deny[msg] {
  # Find S3 buckets in planned changes
  resource := input.resource_changes[_]
  resource.type == "aws_s3_bucket"
  resource.change.actions[_] != "delete"

  # Check if ACL is public
  resource.change.after.acl == "public-read"

  msg := sprintf(
    "SECURITY VIOLATION: S3 bucket '%s' has public-read ACL. All buckets must be private.",
    [resource.address]
  )
}

deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_s3_bucket"
  resource.change.actions[_] != "delete"
  resource.change.after.acl == "public-read-write"

  msg := sprintf(
    "SECURITY VIOLATION: S3 bucket '%s' has public-read-write ACL. This is never allowed.",
    [resource.address]
  )
}


# â”€â”€ Rule 2: S3 must have server-side encryption â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_s3_bucket"
  resource.change.actions[_] != "delete"

  # Check if encryption configuration exists
  not bucket_has_encryption(resource.address)

  msg := sprintf(
    "COMPLIANCE VIOLATION: S3 bucket '%s' must have server-side encryption enabled.",
    [resource.address]
  )
}

# Helper: check if encryption block resource exists for this bucket
bucket_has_encryption(bucket_address) {
  encryption_resource := input.resource_changes[_]
  encryption_resource.type == "aws_s3_bucket_server_side_encryption_configuration"
  encryption_resource.change.after.bucket != null
}


# â”€â”€ Rule 3: S3 versioning required for specific buckets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
warn[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_s3_bucket"
  resource.change.actions[_] != "delete"

  # Check name suggests it's a data bucket
  contains(resource.change.after.bucket, "data")

  # Check versioning status
  versioning := resource.change.after.versioning
  versioning[_].enabled == false

  msg := sprintf(
    "WARNING: Data bucket '%s' should have versioning enabled for compliance.",
    [resource.address]
  )
}
```

```rego
# policies/terraform/aws_security.rego
package terraform.aws

import future.keywords.if
import future.keywords.in

# â”€â”€ Rule 1: EC2 instances must not have public IPs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_instance"
  resource.change.actions[_] != "delete"
  resource.change.after.associate_public_ip_address == true

  msg := sprintf(
    "SECURITY: EC2 instance '%s' must not have a public IP. Use a load balancer instead.",
    [resource.address]
  )
}


# â”€â”€ Rule 2: Security groups must not allow 0.0.0.0/0 on SSH â”€â”€â”€â”€â”€â”€
deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_security_group"
  resource.change.actions[_] != "delete"

  ingress := resource.change.after.ingress[_]
  ingress.from_port <= 22
  ingress.to_port >= 22
  ingress.cidr_blocks[_] == "0.0.0.0/0"

  msg := sprintf(
    "SECURITY VIOLATION: Security group '%s' allows SSH from 0.0.0.0/0. Restrict to VPN CIDR.",
    [resource.address]
  )
}


# â”€â”€ Rule 3: RDS must have multi-AZ in prod â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_db_instance"
  resource.change.actions[_] != "delete"

  # Check environment tag
  resource.change.after.tags.Environment == "prod"

  # Check multi-AZ is not enabled
  resource.change.after.multi_az == false

  msg := sprintf(
    "COMPLIANCE: RDS instance '%s' in prod must have multi_az = true for HA.",
    [resource.address]
  )
}


# â”€â”€ Rule 4: All resources must have required tags â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
required_tags := {"Environment", "Owner", "ManagedBy", "CostCenter"}

taggable_types := {
  "aws_instance",
  "aws_s3_bucket",
  "aws_db_instance",
  "aws_lb",
  "aws_vpc",
  "aws_subnet",
  "aws_security_group",
  "aws_lambda_function",
}

deny[msg] {
  resource := input.resource_changes[_]
  resource.type in taggable_types
  resource.change.actions[_] != "delete"

  # Get actual tags (handle null case)
  tags := object.get(resource.change.after, "tags", {})

  # Find missing required tags
  missing := required_tags - {tag | tags[tag]}
  count(missing) > 0

  msg := sprintf(
    "COMPLIANCE: Resource '%s' (type: %s) is missing required tags: %v",
    [resource.address, resource.type, missing]
  )
}


# â”€â”€ Rule 5: Approved instance types only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
approved_instance_families := {"t3", "t3a", "m5", "m5a", "c5", "r5"}

deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_instance"
  resource.change.actions[_] != "delete"

  instance_type := resource.change.after.instance_type
  family := split(instance_type, ".")[0]

  not approved_instance_families[family]

  msg := sprintf(
    "POLICY: Instance type '%s' for resource '%s' is not in the approved families: %v",
    [instance_type, resource.address, approved_instance_families]
  )
}


# â”€â”€ Rule 6: No destruction of production resources â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
deny[msg] {
  resource := input.resource_changes[_]
  resource.change.actions[_] == "delete"

  # Check if it's a production resource by tag
  resource.change.before.tags.Environment == "prod"

  # Except for specifically whitelisted types
  not allow_prod_deletion(resource.type)

  msg := sprintf(
    "CRITICAL: Destruction of prod resource '%s' (type: %s) requires manual override!",
    [resource.address, resource.type]
  )
}

allow_prod_deletion(resource_type) {
  # These types are OK to delete in prod (e.g., temporary resources)
  allowed_types := {"aws_cloudwatch_metric_alarm", "aws_autoscaling_policy"}
  resource_type in allowed_types
}


# â”€â”€ Rule 7: KMS encryption required for sensitive resources â”€â”€â”€â”€â”€â”€â”€â”€
deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_db_instance"
  resource.change.actions[_] != "delete"

  # Check storage is not encrypted
  not resource.change.after.storage_encrypted

  msg := sprintf(
    "SECURITY: RDS instance '%s' must have storage_encrypted = true.",
    [resource.address]
  )
}

deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_ebs_volume"
  resource.change.actions[_] != "delete"

  not resource.change.after.encrypted

  msg := sprintf(
    "SECURITY: EBS volume '%s' must be encrypted.",
    [resource.address]
  )
}
```

```rego
# policies/terraform/cost_controls.rego
package terraform.cost

import future.keywords.if
import future.keywords.in

# â”€â”€ Rule: Block expensive instance types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
expensive_types := {
  "m5.16xlarge", "m5.24xlarge",
  "c5.18xlarge", "c5.24xlarge",
  "r5.12xlarge", "r5.16xlarge", "r5.24xlarge",
  "p3.8xlarge",  "p3.16xlarge",
  "x1.16xlarge", "x1.32xlarge",
}

deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_instance"
  resource.change.actions[_] != "delete"

  instance_type := resource.change.after.instance_type
  instance_type in expensive_types

  msg := sprintf(
    "COST CONTROL: Instance type '%s' for '%s' exceeds cost limits. Max allowed: m5.4xlarge. Request exception via #infra-requests.",
    [instance_type, resource.address]
  )
}

# â”€â”€ Rule: Multi-AZ RDS only allowed in prod/staging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
warn[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_db_instance"
  resource.change.actions[_] != "delete"
  resource.change.after.multi_az == true

  env := object.get(resource.change.after.tags, "Environment", "unknown")
  env == "dev"

  msg := sprintf(
    "COST WARNING: RDS instance '%s' has multi_az=true in dev environment. Consider single-AZ to reduce costs.",
    [resource.address]
  )
}
```

---

### Integrating OPA into CI/CD Pipeline

```yaml
# .github/workflows/terraform-security.yml
name: Terraform Security & Compliance

on:
  pull_request:
    branches: [main]

jobs:
  security-compliance:
    name: Security & Compliance Checks
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.6.0"
          terraform_wrapper: false

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: us-east-1

      # â”€â”€ Step 1: Generate plan JSON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Terraform Init & Plan
        working-directory: environments/prod
        run: |
          terraform init -input=false
          terraform plan \
            -input=false \
            -out=tfplan \
            -var-file=terraform.tfvars
          terraform show -json tfplan > plan.json

      # â”€â”€ Step 2: OPA/Conftest Policy Check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Install Conftest
        run: |
          VERSION="0.46.0"
          wget -q "https://github.com/open-policy-agent/conftest/releases/download/v${VERSION}/conftest_${VERSION}_Linux_x86_64.tar.gz"
          tar xzf "conftest_${VERSION}_Linux_x86_64.tar.gz"
          sudo mv conftest /usr/local/bin/

      - name: Run OPA Policies
        id: opa
        working-directory: environments/prod
        run: |
          conftest test plan.json \
            --policy ../../policies/terraform/ \
            --output json \
            2>&1 | tee opa_results.json

          # Check exit code
          conftest test plan.json \
            --policy ../../policies/terraform/ \
            --no-color \
            2>&1 | tee opa_results.txt

          echo "exit_code=$?" >> $GITHUB_OUTPUT
        continue-on-error: true

      # â”€â”€ Step 3: tfsec Scan â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Run tfsec
        id: tfsec
        uses: aquasecurity/tfsec-action@v1
        with:
          working_directory: environments/prod
          format: json
          additional_args: --out tfsec-results.json
        continue-on-error: true

      # â”€â”€ Step 4: Checkov Scan â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Run Checkov
        id: checkov
        uses: bridgecrewio/checkov-action@v12
        with:
          directory: environments/prod
          framework: terraform
          output_format: json
          output_file_path: checkov-results.json
          soft_fail: true
        continue-on-error: true

      # â”€â”€ Step 5: Aggregate and Post Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Post Security Report to PR
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // Read OPA results
            let opaOutput = '';
            try {
              opaOutput = fs.readFileSync(
                'environments/prod/opa_results.txt', 'utf8'
              );
            } catch(e) { opaOutput = 'OPA results not found'; }

            const opaStatus = '${{ steps.opa.outputs.exit_code }}' === '0' ? 'âœ…' : 'âŒ';
            const tfsecStatus = '${{ steps.tfsec.outcome }}' === 'success' ? 'âœ…' : 'âš ï¸';
            const checkovStatus = '${{ steps.checkov.outcome }}' === 'success' ? 'âœ…' : 'âš ï¸';

            const body = `## ğŸ” Security & Compliance Report

            | Check | Status |
            |-------|--------|
            | OPA Policy Check | ${opaStatus} |
            | tfsec Security Scan | ${tfsecStatus} |
            | Checkov CIS Benchmark | ${checkovStatus} |

            <details>
            <summary>OPA Policy Details</summary>

            \`\`\`
            ${opaOutput.slice(0, 5000)}
            \`\`\`
            </details>

            ${opaStatus === 'âŒ' ? '> âŒ **OPA policy violations must be resolved before merging.**' : '> âœ… All security checks passed!'}
            `;

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body
            });

      # â”€â”€ Step 6: Fail if critical violations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Fail on OPA Violations
        if: steps.opa.outputs.exit_code != '0'
        run: |
          echo "âŒ OPA policy violations detected! Review the PR comment."
          echo "Run locally: conftest test plan.json --policy ./policies/terraform/"
          exit 1
```

---

### Vault + Terraform â€” Production Patterns

```hcl
# â”€â”€ Pattern 1: Vault Agent Sidecar (K8s) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Vault Agent runs alongside Terraform, manages token renewal
# and injects secrets as environment variables

# vault-agent-config.hcl
# auto_auth {
#   method "kubernetes" {
#     mount_path = "auth/kubernetes"
#     config = {
#       role = "terraform-role"
#     }
#   }
# }
# template {
#   source      = "/vault/templates/aws-creds.tpl"
#   destination = "/vault/secrets/aws-creds.env"
#   command     = "reload-terraform"
# }


# â”€â”€ Pattern 2: Vault Secret Rotation Trigger â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# When Vault rotates a secret, trigger Terraform to update resources

resource "vault_generic_secret" "app_config" {
  path = "secret/myapp/prod"

  data_json = jsonencode({
    api_version = "v2"
    app_name    = "myapp"
    environment = "prod"
  })

  # Disable auto-read on every plan (performance)
  disable_read = false
}

# Watch for changes: Vault webhook â†’ CI/CD â†’ terraform apply


# â”€â”€ Pattern 3: Namespace Isolation per Environment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
provider "vault" {
  address   = "https://vault.mycompany.com"
  namespace = "engineering/${var.environment}"    # Vault Enterprise namespaces
}

# dev â†’ engineering/dev namespace
# prod â†’ engineering/prod namespace â€” completely isolated policies


# â”€â”€ Pattern 4: Break-glass Emergency Access â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# For emergencies when Vault is unavailable:
resource "aws_secretsmanager_secret" "break_glass" {
  name                    = "break-glass/terraform-credentials"
  recovery_window_in_days = 7

  tags = {
    Purpose = "break-glass-emergency-only"
    Audit   = "required"
  }
}

# Access triggers CloudWatch alarm + PagerDuty page
resource "aws_cloudwatch_metric_alarm" "break_glass_accessed" {
  alarm_name          = "break-glass-secret-accessed"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 1
  metric_name         = "CallCount"
  namespace           = "CloudTrailMetrics"
  period              = 60
  statistic           = "Sum"
  threshold           = 0

  alarm_actions = [var.pagerduty_sns_arn]
  alarm_description = "ALERT: Break-glass credentials accessed! Investigate immediately."
}
```

---

## ğŸ”´ ADVANCED LEVEL

### Advanced OPA Patterns

```rego
# policies/terraform/advanced.rego
package terraform.advanced

import future.keywords.if
import future.keywords.in
import future.keywords.every

# â”€â”€ Advanced Rule: Network topology enforcement â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ensure databases are NEVER in public subnets

deny[msg] {
  # Find RDS instances
  db := input.resource_changes[_]
  db.type == "aws_db_instance"
  db.change.actions[_] != "delete"

  # Find subnet group for this DB
  subnet_group := input.resource_changes[_]
  subnet_group.type == "aws_db_subnet_group"
  subnet_group.change.after.name == db.change.after.db_subnet_group_name

  # Find the subnets in the subnet group
  subnet_id := subnet_group.change.after.subnet_ids[_]

  # Check if any subnet is public (has route to internet gateway)
  subnet := input.resource_changes[_]
  subnet.type == "aws_subnet"
  subnet.change.after.id == subnet_id
  subnet.change.after.map_public_ip_on_launch == true

  msg := sprintf(
    "ARCHITECTURE VIOLATION: RDS instance '%s' is placed in a public subnet '%s'. Databases must be in private subnets only.",
    [db.address, subnet_id]
  )
}


# â”€â”€ Advanced Rule: Ensure security group rules are least-privilege â”€
deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_security_group"
  resource.change.actions[_] != "delete"

  # Check each ingress rule
  ingress := resource.change.after.ingress[_]

  # Port range is too broad (more than 100 ports open at once)
  port_range := ingress.to_port - ingress.from_port
  port_range > 100

  # And it's open to a wide CIDR
  cidr := ingress.cidr_blocks[_]
  startswith(cidr, "0.0.0.0") == true

  msg := sprintf(
    "SECURITY: Security group '%s' has an overly broad ingress rule (ports %d-%d open to %s). Use specific ports.",
    [resource.address, ingress.from_port, ingress.to_port, cidr]
  )
}


# â”€â”€ Advanced Rule: Cross-resource relationship validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ensure every EC2 instance has monitoring enabled in prod

deny[msg] {
  instance := input.resource_changes[_]
  instance.type == "aws_instance"
  instance.change.actions[_] != "delete"

  # It's a prod instance
  instance.change.after.tags.Environment == "prod"

  # Check if monitoring is disabled
  not instance.change.after.monitoring

  msg := sprintf(
    "COMPLIANCE: EC2 instance '%s' in prod must have detailed monitoring enabled. Add: monitoring = true",
    [instance.address]
  )
}


# â”€â”€ Advanced Rule: Naming convention enforcement â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
deny[msg] {
  resource := input.resource_changes[_]
  resource.type in {"aws_instance", "aws_s3_bucket", "aws_db_instance", "aws_lb"}
  resource.change.actions[_] != "delete"

  name := resource.change.after.tags.Name

  # Name must match pattern: <app>-<env>-<component>
  # e.g., myapp-prod-web, myapp-dev-db
  not regex.match("^[a-z][a-z0-9]+-(?:dev|staging|prod)-[a-z][a-z0-9-]+$", name)

  msg := sprintf(
    "NAMING: Resource '%s' has invalid Name tag '%s'. Required format: <app>-<env>-<component>",
    [resource.address, name]
  )
}


# â”€â”€ Advanced Rule: IAM policy least privilege â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
deny[msg] {
  resource := input.resource_changes[_]
  resource.type in {"aws_iam_role_policy", "aws_iam_policy"}
  resource.change.actions[_] != "delete"

  # Parse the policy document
  policy := json.unmarshal(resource.change.after.policy)

  statement := policy.Statement[_]
  statement.Effect == "Allow"

  # Check for wildcard action
  statement.Action == "*"

  msg := sprintf(
    "SECURITY: IAM policy '%s' has a wildcard Action ('*'). IAM policies must follow least-privilege.",
    [resource.address]
  )
}

deny[msg] {
  resource := input.resource_changes[_]
  resource.type in {"aws_iam_role_policy", "aws_iam_policy"}
  resource.change.actions[_] != "delete"

  policy := json.unmarshal(resource.change.after.policy)
  statement := policy.Statement[_]
  statement.Effect == "Allow"

  # Check for wildcard resource
  statement.Resource == "*"

  # With non-read-only actions
  action := statement.Action[_]
  not startswith(action, "Get")
  not startswith(action, "List")
  not startswith(action, "Describe")

  msg := sprintf(
    "SECURITY: IAM policy '%s' grants '%s' on all resources ('*'). Restrict to specific resource ARNs.",
    [resource.address, action]
  )
}
```

---

### Compliance Framework Mapping

```rego
# policies/terraform/cis-aws.rego
# Maps to CIS AWS Foundations Benchmark v1.5.0
package terraform.cis

import future.keywords.if
import future.keywords.in

# â”€â”€ CIS 2.1.1: S3 Block Public Access â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_s3_bucket_public_access_block"
  resource.change.actions[_] != "delete"

  not resource.change.after.block_public_acls

  msg := sprintf(
    "[CIS-2.1.1] S3 bucket '%s': block_public_acls must be true",
    [resource.address]
  )
}


# â”€â”€ CIS 2.2.1: EBS Volumes Encrypted â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_ebs_volume"
  resource.change.actions[_] != "delete"
  not resource.change.after.encrypted

  msg := sprintf(
    "[CIS-2.2.1] EBS volume '%s' must be encrypted",
    [resource.address]
  )
}


# â”€â”€ CIS 3.1: CloudTrail Enabled â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# (Check that CloudTrail resource exists in plan)
deny[msg] {
  # Count CloudTrail resources being created
  trails := [r |
    r := input.resource_changes[_]
    r.type == "aws_cloudtrail"
    r.change.actions[_] != "delete"
  ]

  # If we're creating other AWS resources but no CloudTrail
  other_resources := [r |
    r := input.resource_changes[_]
    r.type != "aws_cloudtrail"
    r.change.actions[_] != "delete"
  ]

  count(trails) == 0
  count(other_resources) > 0

  msg := "[CIS-3.1] CloudTrail must be enabled. Add an aws_cloudtrail resource."
}


# â”€â”€ CIS 4.1: No Security Groups Allow SSH from 0.0.0.0/0 â”€â”€â”€â”€â”€â”€â”€â”€â”€
deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_security_group"
  resource.change.actions[_] != "delete"

  ingress := resource.change.after.ingress[_]
  ingress.from_port <= 22
  ingress.to_port >= 22
  ingress.cidr_blocks[_] == "0.0.0.0/0"

  msg := sprintf(
    "[CIS-4.1] Security group '%s' allows SSH (port 22) from 0.0.0.0/0",
    [resource.address]
  )
}


# â”€â”€ CIS 4.2: No Security Groups Allow RDP from 0.0.0.0/0 â”€â”€â”€â”€â”€â”€â”€â”€â”€
deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_security_group"
  resource.change.actions[_] != "delete"

  ingress := resource.change.after.ingress[_]
  ingress.from_port <= 3389
  ingress.to_port >= 3389
  ingress.cidr_blocks[_] == "0.0.0.0/0"

  msg := sprintf(
    "[CIS-4.2] Security group '%s' allows RDP (port 3389) from 0.0.0.0/0",
    [resource.address]
  )
}
```

---

### Building a Complete Security Pipeline

```
COMPLETE SECURITY PIPELINE FLOW:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Developer opens PR
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Static Analysis â”‚  terraform validate + tflint
â”‚  (pre-plan)      â”‚  Catches syntax errors, bad practices
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Terraform Plan  â”‚  Generate plan.json
â”‚                  â”‚  Uses Vault for dynamic credentials
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Security Scan   â”‚  tfsec + Checkov + custom rules
â”‚  (post-plan)     â”‚  Scan plan.json for known vulnerabilities
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OPA/Conftest    â”‚  Custom business + compliance policies
â”‚  Policy Check    â”‚  CIS benchmark, naming, tagging, cost
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ All checks pass?
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PR Review       â”‚  Human review of plan + security report
â”‚  (human gate)    â”‚  Required: 2 approvers for prod
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Approved
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sentinel Check  â”‚  (If using TF Cloud/Enterprise)
â”‚  (pre-apply)     â”‚  Final policy gate before apply
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Apply           â”‚  terraform apply
â”‚                  â”‚  Vault issues temp credentials
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Post-Apply      â”‚  Verify outputs
â”‚  Verification    â”‚  Run infrastructure tests
â”‚                  â”‚  Update CMDB/asset registry
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Audit & Alert   â”‚  All actions logged to Vault audit
â”‚                  â”‚  CloudTrail records API calls
â”‚                  â”‚  Slack notification to team
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Production Best Practices

```hcl
# âœ… 1. Never store Vault tokens in files â€” use env vars or auth methods
# export VAULT_ADDR=https://vault.mycompany.com
# export VAULT_TOKEN=$(vault login -method=aws -field=token)

# âœ… 2. Set appropriate TTLs for dynamic credentials
resource "vault_database_secret_backend_role" "app" {
  default_ttl = "2h"     # Enough for longest apply
  max_ttl     = "24h"    # Hard maximum

  # If apply takes 90 min, TTL=2h gives plenty of buffer
}

# âœ… 3. Use OPA warn[] for advisory, deny[] for blocking
# warn  â†’ shows in output, doesn't block apply
# deny  â†’ blocks apply entirely

# âœ… 4. Version-pin your policy files (keep in Git with semantic versions)
# policies/
# â”œâ”€â”€ v1.0.0/
# â”‚   â”œâ”€â”€ aws_security.rego
# â”‚   â””â”€â”€ tagging.rego
# â””â”€â”€ v1.1.0/
#     â”œâ”€â”€ aws_security.rego  (updated)
#     â””â”€â”€ tagging.rego

# âœ… 5. Test OPA policies with conftest verify
# Create test files:
# policies/terraform/aws_security_test.rego

# âœ… 6. Separate policy repos from infrastructure repos
# infra-policies/ (separate repo, policy team owns)
# â”œâ”€â”€ README.md
# â”œâ”€â”€ policies/
# â””â”€â”€ tests/
#
# my-infrastructure/ (app team owns)
# Uses policies as a submodule or downloads from registry

# âœ… 7. Use Vault namespaces for environment isolation (Enterprise)
provider "vault" {
  namespace = "engineering/${var.environment}"
}

# âœ… 8. Implement policy exceptions as code (not verbal approvals)
# exceptions.json
# {
#   "exception_id": "EXC-2024-001",
#   "resource": "aws_instance.legacy",
#   "policy": "restrict-instance-types",
#   "reason": "Legacy workload requires t2.medium â€” migration planned Q2 2024",
#   "approved_by": "jane.smith@company.com",
#   "expires": "2024-06-30"
# }
```

---

### Debugging Security & Compliance Issues

```bash
# â”€â”€ Debug OPA Policies â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Test a specific policy against plan
conftest test plan.json \
  --policy ./policies/terraform/aws_security.rego \
  --trace    # Show evaluation trace

# Test with verbose output
conftest test plan.json \
  --policy ./policies/terraform/ \
  --output table \
  --all-namespaces

# Interactive OPA evaluation
opa eval \
  --data ./policies/terraform/aws_security.rego \
  --input plan.json \
  "data.terraform.aws.deny" \
  --format pretty

# Test individual rules
opa eval \
  --data ./policies/terraform/aws_security.rego \
  --input plan.json \
  'data.terraform.aws.deny[x]' \
  --format pretty


# â”€â”€ Debug Vault Issues â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Check Vault status
vault status

# Verify auth method works
vault login -method=aws -field=token

# Test secret access manually
vault read secret/data/myapp/prod/config

# Check policies attached to token
vault token lookup

# Verify dynamic DB credentials work
vault read database/creds/app-role

# View audit logs
vault audit list
tail -f /var/log/vault/audit.log | jq .


# â”€â”€ Debug Sentinel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Test Sentinel policy locally (requires Sentinel CLI)
sentinel test ./policies/restrict-instance-types.sentinel

# Apply with policy override (soft-mandatory only)
# In Terraform Cloud UI: "Override & Continue" button
# Requires "policy-override" permission on the team


# â”€â”€ Common Errors and Fixes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Error: "permission denied" in Vault
# Fix: Check Vault policy attached to your auth method's role
vault policy read terraform-policy

# Error: "lease expired during apply"
# Fix: Increase TTL on the secret engine role
# Or: Use Vault Agent to auto-renew leases

# Error: "conftest: no files provided"
# Fix: Generate plan.json first:
terraform show -json tfplan > plan.json
conftest test plan.json --policy ./policies/

# Error: OPA policy "undefined" result
# Fix: Check package name matches conftest namespace
# package terraform.aws â†’ conftest test --namespace terraform.aws
```

---

## ğŸ“ CODE WRITING GUIDANCE

### Complete Security Project Structure

```
infrastructure/
â”‚
â”œâ”€â”€ policies/                          â† Policy repository
â”‚   â”œâ”€â”€ terraform/
â”‚   â”‚   â”œâ”€â”€ aws_security.rego          â† Security rules
â”‚   â”‚   â”œâ”€â”€ cis_aws.rego               â† CIS benchmark
â”‚   â”‚   â”œâ”€â”€ tagging.rego               â† Tagging policy
â”‚   â”‚   â”œâ”€â”€ cost_controls.rego         â† Cost policies
â”‚   â”‚   â”œâ”€â”€ naming_conventions.rego    â† Naming standards
â”‚   â”‚   â””â”€â”€ tests/                     â† Policy unit tests
â”‚   â”‚       â”œâ”€â”€ aws_security_test.rego
â”‚   â”‚       â””â”€â”€ fixtures/
â”‚   â”‚           â”œâ”€â”€ pass_plan.json     â† Valid plan for testing
â”‚   â”‚           â””â”€â”€ fail_plan.json     â† Invalid plan for testing
â”‚   â”‚
â”‚   â”œâ”€â”€ sentinel/                      â† TFC/TFE policies
â”‚   â”‚   â”œâ”€â”€ sentinel.hcl
â”‚   â”‚   â”œâ”€â”€ restrict-instance-types.sentinel
â”‚   â”‚   â”œâ”€â”€ require-tags.sentinel
â”‚   â”‚   â””â”€â”€ modules/
â”‚   â”‚       â””â”€â”€ aws-functions.sentinel
â”‚   â”‚
â”‚   â””â”€â”€ exceptions/                    â† Approved exceptions
â”‚       â””â”€â”€ exceptions.json
â”‚
â”œâ”€â”€ vault/                             â† Vault configuration
â”‚   â”œâ”€â”€ main.tf                        â† Vault resources
â”‚   â”œâ”€â”€ auth-methods.tf                â† AppRole, AWS, K8s auth
â”‚   â”œâ”€â”€ secret-engines.tf              â† KV, AWS, DB engines
â”‚   â”œâ”€â”€ policies/                      â† Vault HCL policies
â”‚   â”‚   â”œâ”€â”€ terraform-dev.hcl
â”‚   â”‚   â”œâ”€â”€ terraform-prod.hcl
â”‚   â”‚   â””â”€â”€ readonly.hcl
â”‚   â””â”€â”€ audit.tf                       â† Audit configuration
â”‚
â”œâ”€â”€ environments/
â”‚   â””â”€â”€ prod/
â”‚       â”œâ”€â”€ main.tf                    â† Uses Vault provider
â”‚       â”œâ”€â”€ vault.tf                   â† Vault data sources
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â”œâ”€â”€ security-scan.yml          â† OPA + tfsec + checkov
        â””â”€â”€ terraform-apply.yml        â† Applies with Vault auth
```

---

## ğŸ§ª HANDS-ON LAB

### Exercise: Complete Security Pipeline

**Goal:** Build a security-first Terraform setup with:
1. Three OPA policies: no-public-s3, required-tags, approved-instance-types
2. A GitHub Actions workflow that runs OPA checks on every PR
3. A Vault data source reading a KV secret (can mock with local Vault dev server)
4. Generate a plan, run it through conftest, and see pass/fail output

**Setup:**
```bash
# Start local Vault dev server (for testing)
vault server -dev -dev-root-token-id="dev-root-token"
export VAULT_ADDR="http://127.0.0.1:8200"
export VAULT_TOKEN="dev-root-token"

# Create test secret
vault kv put secret/myapp/dev \
  api_key="test-api-key-12345" \
  db_password="test-db-password-67890"

# Install conftest
brew install conftest
```

**Try implementing the policies and pipeline yourself!**

---

### âœ… Solution

```rego
# policies/terraform/main.rego
package main

import future.keywords.if
import future.keywords.in

# â”€â”€ Policy 1: No Public S3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_s3_bucket"
  resource.change.actions[_] != "delete"

  acl := object.get(resource.change.after, "acl", "private")
  acl in {"public-read", "public-read-write", "authenticated-read"}

  msg := sprintf(
    "âŒ [S3-PUBLIC] Bucket '%s' has ACL '%s'. All buckets must be private.",
    [resource.address, acl]
  )
}

deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_s3_bucket_public_access_block"
  resource.change.actions[_] != "delete"

  not resource.change.after.block_public_acls

  msg := sprintf(
    "âŒ [S3-PUBLIC] Resource '%s': block_public_acls must be true",
    [resource.address]
  )
}


# â”€â”€ Policy 2: Required Tags â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
required_tags := {"Environment", "Owner", "ManagedBy"}

taggable_types := {
  "aws_instance", "aws_s3_bucket",
  "aws_db_instance", "aws_vpc", "aws_lb"
}

deny[msg] {
  resource := input.resource_changes[_]
  resource.type in taggable_types
  resource.change.actions[_] != "delete"

  tags := object.get(resource.change.after, "tags", {})
  missing := required_tags - {tag | tags[tag]}
  count(missing) > 0

  msg := sprintf(
    "âŒ [TAGS] Resource '%s' missing required tags: %v",
    [resource.address, missing]
  )
}


# â”€â”€ Policy 3: Approved Instance Types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
approved_types := {
  "t3.micro", "t3.small", "t3.medium", "t3.large",
  "m5.large", "m5.xlarge", "m5.2xlarge"
}

deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_instance"
  resource.change.actions[_] != "delete"

  instance_type := resource.change.after.instance_type
  not instance_type in approved_types

  msg := sprintf(
    "âŒ [COST] Instance type '%s' for '%s' not approved. Approved: %v",
    [instance_type, resource.address, approved_types]
  )
}

# â”€â”€ Warnings (non-blocking) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
warn[msg] {
  resource := input.resource_changes[_]
  resource.type == "aws_instance"
  resource.change.actions[_] != "delete"

  not resource.change.after.monitoring

  msg := sprintf(
    "âš ï¸  [MONITORING] Instance '%s' should have monitoring = true",
    [resource.address]
  )
}
```

```hcl
# main.tf â€” Test infrastructure (intentionally has violations)
provider "aws" { region = "us-east-1" }

# âŒ VIOLATION: Public S3 bucket
resource "aws_s3_bucket" "bad_bucket" {
  bucket = "my-public-bucket-test"
  acl    = "public-read"   # â† Will be caught by policy
  # Missing required tags! â† Will be caught by policy
}

# âœ… COMPLIANT: Proper bucket
resource "aws_s3_bucket" "good_bucket" {
  bucket = "my-private-bucket-test"

  tags = {
    Environment = "dev"
    Owner       = "devops-team"
    ManagedBy   = "Terraform"
  }
}

resource "aws_s3_bucket_public_access_block" "good_bucket" {
  bucket                  = aws_s3_bucket.good_bucket.id
  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

# âŒ VIOLATION: Unapproved instance type + missing tags
resource "aws_instance" "bad_instance" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "m5.24xlarge"    # â† Not approved!
  # Missing tags â† Caught!
}
```

```bash
# Run the lab:
terraform init
terraform plan -out=tfplan
terraform show -json tfplan > plan.json

# Run OPA checks
conftest test plan.json --policy ./policies/terraform/

# Expected output:
# FAIL - plan.json - main - âŒ [S3-PUBLIC] Bucket 'aws_s3_bucket.bad_bucket' has ACL 'public-read'
# FAIL - plan.json - main - âŒ [TAGS] Resource 'aws_s3_bucket.bad_bucket' missing required tags: {"Environment", "ManagedBy", "Owner"}
# FAIL - plan.json - main - âŒ [COST] Instance type 'm5.24xlarge' for 'aws_instance.bad_instance' not approved
# FAIL - plan.json - main - âŒ [TAGS] Resource 'aws_instance.bad_instance' missing required tags: ...
# WARN - plan.json - main - âš ï¸  [MONITORING] Instance 'aws_instance.bad_instance' should have monitoring = true
# 5 tests, 0 passed, 1 warning, 4 failures
```

```yaml
# .github/workflows/security.yml
name: Security & Compliance

on:
  pull_request:
    branches: [main]

jobs:
  opa-check:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.6.0"
          terraform_wrapper: false

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: us-east-1

      - name: Terraform Plan
        run: |
          terraform init -input=false
          terraform plan -out=tfplan -input=false -var-file=terraform.tfvars
          terraform show -json tfplan > plan.json

      - name: Install Conftest
        run: |
          wget -q https://github.com/open-policy-agent/conftest/releases/download/v0.46.0/conftest_0.46.0_Linux_x86_64.tar.gz
          tar xzf conftest_0.46.0_Linux_x86_64.tar.gz && sudo mv conftest /usr/local/bin/

      - name: Run OPA Policies
        id: opa
        run: |
          conftest test plan.json \
            --policy ./policies/terraform/ \
            --no-color 2>&1 | tee opa_results.txt
          echo "exit_code=$?" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Post Results to PR
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const results = fs.readFileSync('opa_results.txt', 'utf8');
            const passed = '${{ steps.opa.outputs.exit_code }}' === '0';
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: `## ${passed ? 'âœ…' : 'âŒ'} OPA Policy Results\n\`\`\`\n${results}\n\`\`\``
            });

      - name: Fail if violations
        if: steps.opa.outputs.exit_code != '0'
        run: exit 1
```

---

## ğŸ“‹ SUMMARY CHEAT SHEET

### Key Points

| Tool | Purpose | Works With | Key Feature |
|---|---|---|---|
| **Vault** | Secrets management | All Terraform | Dynamic secrets, auto-expiry, audit logs |
| **Sentinel** | Policy enforcement | TFC/TFE only | Native integration, cost estimation |
| **OPA/Conftest** | Policy enforcement | Any CI/CD | Open source, multi-system, Rego language |
| **tfsec** | Security scanning | Any | AWS/Azure/GCP rule library |
| **Checkov** | Compliance scanning | Any | CIS benchmarks, SOC2, HIPAA |

---

### Quick Reference

```bash
# Vault
vault server -dev                             # Start dev server
vault kv put secret/path key=value           # Store secret
vault kv get secret/path                     # Read secret
vault read database/creds/my-role            # Get dynamic DB creds
vault token lookup                            # Check current token

# OPA/Conftest
terraform show -json tfplan > plan.json       # Generate plan JSON
conftest test plan.json --policy ./policies/  # Run all policies
conftest test plan.json --policy file.rego    # Run specific policy
conftest test plan.json --output table        # Table format
conftest test plan.json --trace               # Debug trace
opa eval -d policy.rego -i plan.json "data.pkg.deny"  # Direct OPA eval

# Sentinel (TFC/TFE)
sentinel test ./policies/                     # Test policies locally
sentinel apply -config=sentinel.hcl          # Apply policies

# Security Scanners
tfsec . --severity HIGH                       # High severity only
checkov -d . --framework terraform            # Checkov scan
```

```rego
# OPA Policy Template
package main                          # or: package terraform.aws

import future.keywords.if
import future.keywords.in

# Block (hard)
deny[msg] {
  resource := input.resource_changes[_]
  resource.type == "RESOURCE_TYPE"
  resource.change.actions[_] != "delete"
  # YOUR CONDITION
  msg := sprintf("Error message for %s", [resource.address])
}

# Warn (soft)
warn[msg] {
  resource := input.resource_changes[_]
  # YOUR CONDITION
  msg := sprintf("Warning for %s", [resource.address])
}
```

---

### Top 10 Interview Questions

1. **What is the difference between Vault static and dynamic secrets?** Static secrets are stored key-value pairs that don't change unless manually rotated. Dynamic secrets are generated on-demand with a TTL â€” Vault creates a temporary credential (e.g., DB user), and automatically destroys it when the lease expires.

2. **How does Vault AppRole authentication work?** AppRole uses a `role_id` (like a username) and `secret_id` (like a password). CI/CD pipelines use AppRole to authenticate â€” `role_id` is static and stored in code, `secret_id` is dynamic and rotated regularly.

3. **What's the difference between Sentinel and OPA?** Sentinel is HashiCorp-native, runs only in Terraform Cloud/Enterprise, has tighter plan integration and cost estimation. OPA is open-source, works with any system, uses Rego language, and integrates via Conftest in any CI/CD pipeline.

4. **What are Sentinel enforcement levels?** Advisory (always passes, logs violations), soft-mandatory (blocks unless senior engineer overrides), hard-mandatory (always blocks, cannot be overridden by anyone).

5. **How do you handle Vault lease expiry during a long Terraform apply?** Set the credential TTL longer than your longest expected apply (e.g., TTL=4h for a 90-minute apply). Alternatively, use Vault Agent which automatically renews leases while Terraform runs.

6. **What does `terraform show -json tfplan > plan.json` produce?** A machine-readable JSON representation of the Terraform plan, including all resource changes, before/after values, and actions. This is what OPA/Conftest policies evaluate.

7. **How do you test OPA policies without running Terraform?** Create fixture JSON files (`pass_plan.json` and `fail_plan.json`) that simulate plan output, then run `conftest test pass_plan.json --policy ./policies/` and `conftest verify` to unit-test your Rego rules.

8. **What is the Vault Transit secrets engine?** A "encryption as a service" engine that lets applications encrypt and decrypt data without having access to the encryption key itself. Useful for encrypting sensitive values before storing them in Terraform state.

9. **How do you implement policy exceptions without bypassing security?** Code policy exceptions as structured data in a JSON file with fields like `exception_id`, `resource`, `reason`, `approved_by`, and `expires`. OPA policies check the exceptions file and allow the resource if a valid, non-expired exception exists.

10. **What is OIDC and how does it relate to Vault and CI/CD?** OpenID Connect is a federated identity protocol. GitHub Actions, GitLab, and others issue JWT tokens that Vault and AWS can verify directly â€” eliminating the need for static credentials entirely. CI/CD authenticates to Vault via OIDC, Vault issues dynamic cloud credentials, Terraform uses them to apply.

---
